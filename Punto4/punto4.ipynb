{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://unal.edu.co/_assets/ca8e1ca9a551c3e3ffc233b30e54ba93/images/escudoUnal.svg\" width=\"800\" height=\"500\">\n",
    "\n",
    "# LABORATORIO 1\n",
    "\n",
    "## Gustavo Arteaga \n",
    "## Universidad Nacional de Colombia - Facultad de minas \n",
    "## Tópicos Azanzados de Procesamiento Digital de Señales\n",
    "### 2024-03-14\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Simulación de la Localización Binaural\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actividades:\n",
    "\n",
    "##### Se propone justamente descargar o generar un sonido monofónico (un canal) de corta duración y procesarlo para generar una señal de dos canales (estéreo). El propósito del procesamiento debe ser el de generar una sensación de localización de dicho sonido, a partir de la manipulación de sus valores relativos de relativos de amplitud y desfase.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ Solución "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar y reproducir sonido de un solo canal (Lado Derecho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import simpleaudio as sa\n",
    "\n",
    "# Convertir el archivo MP3 a WAV para compatibilidad\n",
    "audio = AudioSegment.from_mp3(\"monofonico_canal_R.mp3\")\n",
    "audio.export(\"monofonico_canal_R.wav\", format=\"wav\")\n",
    "\n",
    "# Cargar y reproducir el archivo WAV\n",
    "wave_obj = sa.WaveObject.from_wave_file(\"monofonico_canal_R.wav\")\n",
    "play_obj = wave_obj.play()\n",
    "play_obj.wait_done()  # Espera a que termine de reproducirse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráfica sonido de un solo canal (Lado Derecho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# Cargar el archivo de audio\n",
    "sample_rate, data = wavfile.read(\"monofonico_canal_R.wav\")\n",
    "duration = len(data) / sample_rate\n",
    "time = np.arange(0, duration, 1/sample_rate)\n",
    "\n",
    "# Graficar la señal en el tiempo\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(time, data)\n",
    "plt.title('Señal de Audio monofónico canal R en el Tiempo')\n",
    "plt.ylabel('Amplitud')\n",
    "plt.xlabel('Tiempo (s)')\n",
    "\n",
    "# Calcular y graficar la FFT\n",
    "yf = fft(data)\n",
    "xf = fftfreq(len(data), 1 / sample_rate)\n",
    "\n",
    "# Graficar la amplitud del espectro de frecuencias\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(xf, np.abs(yf))\n",
    "plt.title('Espectro de Amplitud')\n",
    "plt.xlabel('Frecuencia (Hz)')\n",
    "plt.ylabel('Amplitud')\n",
    "\n",
    "# Graficar la fase del espectro de frecuencias\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(xf, np.angle(yf))\n",
    "plt.title('Espectro de Fase')\n",
    "plt.xlabel('Frecuencia (Hz)')\n",
    "plt.ylabel('Fase (radianes)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convertir señal de sonido monofónico a canal izquierdo L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "\n",
    "# Leer el archivo monofonico_canal_R.wav\n",
    "fs, data = wavfile.read(\"monofonico_canal_R.wav\")\n",
    "\n",
    "# Extraer la información del canal derecho \n",
    "right_channel = data if len(data.shape) == 1 else data[:, 1]\n",
    "\n",
    "# Crear un array estéreo con el canal derecho en el izquierdo y silencio en el derecho\n",
    "# Para silencio usamos un array de ceros con la misma longitud que el canal derecho\n",
    "stereo_data = np.zeros((len(right_channel), 2), dtype=right_channel.dtype)\n",
    " # Canal izquierdo\n",
    "stereo_data[:, 0] = right_channel \n",
    "\n",
    "# Exportar a un nuevo archivo WAV\n",
    "wavfile.write(\"reproducir_en_canal_izquierdo.wav\", fs, stereo_data)\n",
    "\n",
    "# Código para reproducir el archivo modificado usando simpleaudio\n",
    "wave_obj = sa.WaveObject.from_wave_file(\"reproducir_en_canal_izquierdo.wav\")\n",
    "play_obj = wave_obj.play()\n",
    "play_obj.wait_done()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Grafica onda Stereo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graficar la señal en el tiempo\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(time, stereo_data[:, 0])\n",
    "plt.title('Señal de Audio en el Canal Izquierdo')\n",
    "plt.ylabel('Amplitud')\n",
    "plt.xlabel('Tiempo (s)')\n",
    "plt.show()\n",
    "\n",
    "# Calcular y graficar la FFT\n",
    "yf = fft(stereo_data[:, 0])\n",
    "xf = fftfreq(len(stereo_data[:, 0]), 1 / fs)\n",
    "\n",
    "# Graficar la amplitud del espectro de frecuencias\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(xf, np.abs(yf))\n",
    "plt.title('Espectro de Amplitud')\n",
    "plt.xlabel('Frecuencia (Hz)')\n",
    "plt.ylabel('Amplitud')\n",
    "\n",
    "# Graficar la fase del espectro de frecuencias\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(xf, np.angle(yf))\n",
    "plt.title('Espectro de Fase')\n",
    "plt.xlabel('Frecuencia (Hz)')\n",
    "plt.ylabel('Fase (radianes)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensación de localización  modificando fase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import simpleaudio as sa\n",
    "\n",
    "# Leer el archivo WAV original\n",
    "fs, data = wavfile.read(\"monofonico_canal_R.wav\")\n",
    "\n",
    "# Extraer el canal derecho (o el canal único si es monofónico)\n",
    "right_channel = data if len(data.shape) == 1 else data[:, 1]\n",
    "\n",
    "# Crear un array estéreo\n",
    "stereo_data = np.zeros((len(right_channel), 2), dtype=right_channel.dtype)\n",
    "\n",
    "# Calcular el número de muestras para el retardo\n",
    "delay_samples = int(0.05e-3 * fs)  # 0.5 milisegundos de retardo\n",
    "\n",
    "# Crear un efecto de espacialidad\n",
    "# Copiar el canal derecho al izquierdo con retardo para el efecto de espacialidad\n",
    "stereo_data[delay_samples:, 0] = right_channel[:-delay_samples]\n",
    "# Mantener el canal derecho sin cambios\n",
    "stereo_data[:, 1] = right_channel\n",
    "\n",
    "# Exportar a un nuevo archivo WAV\n",
    "wavfile.write(\"efecto_espacialidad.wav\", fs, stereo_data)\n",
    "\n",
    "# Código para reproducir el archivo modificado\n",
    "wave_obj = sa.WaveObject.from_wave_file(\"efecto_espacialidad.wav\")\n",
    "play_obj = wave_obj.play()\n",
    "play_obj.wait_done()  # Espera a que termine de reproducirse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
